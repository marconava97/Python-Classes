{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled23.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### **Joining DataFrames with merge**\n"
      ],
      "metadata": {
        "id": "qfH68m6HNqMC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already have all of our data sets each saved in a .csv file. Each one contains information that the others do not, so we need a way to link them together so that one set can complement the information that another lacks.\n",
        "\n",
        "Let's read 2 of our datasets:\n"
      ],
      "metadata": {
        "id": "Wb5V-lxMNxL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "dwF8XiB4Nmm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users = pd.read_csv('../../Datasets/MovieLens/users-raw.csv', index_col=0, names=['gender', 'age', 'occupation', 'cp'])\n"
      ],
      "metadata": {
        "id": "AcRqYVJ8OSWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.index.name = 'user_id'"
      ],
      "metadata": {
        "id": "wttqz7tMOU42"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occupations = pd.read_csv('../../Datasets/MovieLens/occupations-raw.csv', index_col=0, names=['description'])\n"
      ],
      "metadata": {
        "id": "guDSl_ZcOW2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occupations.index.name = 'occupation_id'\n"
      ],
      "metadata": {
        "id": "jtZa8omTOZAR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.head()"
      ],
      "metadata": {
        "id": "hqDaaHY0Ob9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "occupations.head()"
      ],
      "metadata": {
        "id": "YA6CyllqOdmL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "users contains a column named occupation that has codes that correspond to an index of the occupations table. Each code is mapped to a textual description of the occupation.\n"
      ],
      "metadata": {
        "id": "qhWxizr1Oxpp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_full = pd.merge(users, occupations, left_on='occupation', right_index=True).sort_index()\n"
      ],
      "metadata": {
        "id": "YJ8V5VyfO3sl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_full\n"
      ],
      "metadata": {
        "id": "kRLTegyHO56s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we could change our column names to be more descriptive:\n"
      ],
      "metadata": {
        "id": "F-S624D0PDmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users_full = users_full.rename(columns={'occupation': 'occupation_id', 'description': 'occupation'})\n"
      ],
      "metadata": {
        "id": "vK-lYZfEPEaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_full\n"
      ],
      "metadata": {
        "id": "S4tt0rClYoeg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Grouping data with groupby**\n",
        "\n"
      ],
      "metadata": {
        "id": "T0_bos91ZCaM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users = pd.read_csv('../../Datasets/MovieLens/users-full.csv', index_col=0)\n",
        "\n",
        "users"
      ],
      "metadata": {
        "id": "22INU-0GZCkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby('gender')\n"
      ],
      "metadata": {
        "id": "yC-Q2JIhZNRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby('gender').size()\n"
      ],
      "metadata": {
        "id": "AL4LsxYFZjPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also request specific columns from our groups and apply aggregations to each column:\n"
      ],
      "metadata": {
        "id": "sN5QCgIaZm_O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby('gender')['occupation'].value_counts()\n"
      ],
      "metadata": {
        "id": "pURJ6EdqZosw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use two or more columns to group as well. What happens is that the dataset is grouped using the first column, and then, within each group, a second grouping is done using the second column:\n"
      ],
      "metadata": {
        "id": "MrdUtt1WZvbN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby(['gender', 'age_range'])['occupation'].value_counts()\n"
      ],
      "metadata": {
        "id": "Iz3AKlYFZv7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_ga_counts.loc['F']\n"
      ],
      "metadata": {
        "id": "DsK0jEYXaQUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "users_ga_counts.loc[('F', '18-24')]\n"
      ],
      "metadata": {
        "id": "H0Za8-WraU5-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, not all functions are available \"out-of-the-box\" to be applied to groupby objects. There are some functions that we cannot use directly and in order to apply them we need to use the agg method. agg receives a function or a list of functions and applies them to the requested columns in each group.\n"
      ],
      "metadata": {
        "id": "ehdoToSbab8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby('gender')['occupation'].agg(pd.Series.mode)\n"
      ],
      "metadata": {
        "id": "zVGtZXalacie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can apply the function to two columns at the same time:\n"
      ],
      "metadata": {
        "id": "QiMlHFD_anmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby('gender')[['age_range', 'occupation']].agg(pd.Series.mode)\n"
      ],
      "metadata": {
        "id": "pbKwAn4GaqDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "And we can also apply multiple functions at the same time by passing a list of functions to agg. In this case we are going to use some statistical analysis on the age_id column. Actually these analyzes are not going to be precise because this column contains ids that represent age ranges, not ages as such. But consider it a simple example to see how the tools work:\n"
      ],
      "metadata": {
        "id": "oDCFjWLiav23"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "users.groupby('gender')['age_id'].agg(['mean', 'median', 'std'])\n"
      ],
      "metadata": {
        "id": "LGc_HLv5av-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Location estimators**"
      ],
      "metadata": {
        "id": "jQoaa47xbHNg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Location estimators help us determine which value best describes a data set. We call this value the \"typical value\" of our set. Two estimates are the most common and most used:\n",
        "\n",
        "Average (or mean)\n",
        "Median\n",
        "Let's see how they are calculated using pandas."
      ],
      "metadata": {
        "id": "gO5pFy7VbHul"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../../Datasets/melbourne_housing-clean.csv', index_col=0)\n"
      ],
      "metadata": {
        "id": "uERup00bbRUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "rq0lT3mGbU2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MEAN**"
      ],
      "metadata": {
        "id": "XRWH_IKmbcbk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The mean or average is obtained by adding all the values ​​of a numerical data set and dividing them by the number of values ​​that we have in our set.\n"
      ],
      "metadata": {
        "id": "Q6obV6d_bXtt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's analyze the price column. Let's see what is the \"typical value\" obtained using the mean (average):\n"
      ],
      "metadata": {
        "id": "WXOwwHd6br0d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['price'].mean()\n"
      ],
      "metadata": {
        "id": "yz2epwqHbsj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**MEDIAN**"
      ],
      "metadata": {
        "id": "WnP5GePMbz4C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The median is obtained as follows:\n",
        "\n",
        "First we sort our data in ascending order.\n",
        "We then take the value that is right in the middle of our ordered sequence of values.\n",
        "If our set has an even number of values ​​and therefore does not have a value right in the middle of the sequence, we take the average of the two values ​​that are in the middle of the sequence.\n",
        "Now let's look at the \"typical value\" obtained using the median:\n"
      ],
      "metadata": {
        "id": "0184_K5Ob2VN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['price'].median()\n"
      ],
      "metadata": {
        "id": "vGn80vaOb3Kp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Truncated Mean**\n"
      ],
      "metadata": {
        "id": "Ec7GkT27cApU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The trimmed mean is a more robust estimate of location than the mean and median. This means that it is less sensitive to outliers. The trimmed mean is obtained as follows:\n",
        "\n",
        "We first order our set in ascending order.\n",
        "We then decide what percentage of our data we are going to truncate. The most common values ​​usually vary between 5% and 25%.\n",
        "Divide the agreed percentage by two and remove that fraction of your data from the start and end of your sequence. For example, if you decide to truncate 5%, remove 2.5% of your data from the start of your stream and 2.5% from the end of your stream.\n",
        "Get the average of the remaining values.\n"
      ],
      "metadata": {
        "id": "XHFZ3Oj6cKJu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fortunately, we don't have to do this manually. The scipy library already offers a method to get the truncated mean easily:\n"
      ],
      "metadata": {
        "id": "WFVLX-L5cN73"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import stats\n"
      ],
      "metadata": {
        "id": "oarhQXRbcOo9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "xRnyJafKcUK3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stats.trim_mean(df['price'], 0.1)\n"
      ],
      "metadata": {
        "id": "NpNYnFy-cWvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Standard deviation**\n"
      ],
      "metadata": {
        "id": "mB7CeN2Vch-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the standard deviation, the following steps are carried out:\n",
        "\n",
        "- First we obtain the average of our data.\n",
        "- We then extract all the differences between each value in our set and our typical value.\n",
        "- Then we square all the results.\n",
        "- Then all these values ​​are added.\n",
        "- They are then divided by the number of values ​​- 1.\n",
        "- Finally, the square root of the resulting value is taken.\n"
      ],
      "metadata": {
        "id": "gKanxQVucjsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['price'].std()\n"
      ],
      "metadata": {
        "id": "5N-v_feNct6D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The higher our result means that our data is more dispersed (that is, there are many data that are far from our typical value); the lower the result means that our data is less spread out (that is, they are closer to our typical value).\n",
        "\n",
        "Obviously we have to take into account the range of our values ​​to determine if our standard deviation is small or large. For example, a standard deviation of 10 is very small if our values ​​have a range of 1,000,000. By contrast, a standard deviation of 10 is much larger if our values ​​have a range of 40.\n"
      ],
      "metadata": {
        "id": "9Cbex_Z4cxSv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CORRELATION**"
      ],
      "metadata": {
        "id": "rTQPAy5rds9g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We say that two variables are positively correlated if the increase in values ​​in one of them is related to the increase in values ​​in the other; and if the decrease in values ​​in one is related to the decrease in values ​​in the other.\n",
        "\n",
        "Instead, we say that they are negatively correlated if the increase in the values ​​of one is related to the decrease in the values ​​of the other, and vice versa.\n"
      ],
      "metadata": {
        "id": "p_lf9kWzdu70"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "sns.set_style('white')"
      ],
      "metadata": {
        "id": "p6X-ynKMhc7i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_1_1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "arr_1_2 = pd.Series([10, 9, 8, 7, 6, 5, 4, 3, 2, 1])\n",
        "\n",
        "plt.scatter(arr_1_1, arr_1_2, c='m');\n",
        "plt.plot(arr_1_1, arr_1_2, c='c');"
      ],
      "metadata": {
        "id": "hkDkkhQYhsOx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_2_1 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "arr_2_2 = pd.Series([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\n",
        "\n",
        "plt.scatter(arr_2_1, arr_2_2, c='m');\n",
        "plt.plot(arr_2_1, arr_2_2, c='c');"
      ],
      "metadata": {
        "id": "ZQR91M9ihuVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "arr_3_1 = pd.Series([1, 7, 1, 22, 54, 2, 7, 26, 3, 13, 37, 87, 63, 15, 16, 74, 56, 95, 78, 61, 12, 43, 63, 84])\n",
        "arr_3_2 = pd.Series([64, 43, 12, 4, 75, 46, 94, 46, 24, 5, 85, 67, 98, 15, 12, 53, 3, 85, 36, 24, 74, 57, 64, 13])\n",
        "\n",
        "plt.scatter(arr_3_1, arr_3_2, c='m');"
      ],
      "metadata": {
        "id": "MTpu_C-hhwhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Correlation between the first two Series: {arr_1_1.corr(arr_1_2)}')\n"
      ],
      "metadata": {
        "id": "bz-U2B9Oh0Nk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Correlation between the second two Series: {arr_2_1.corr(arr_2_2)}')\n"
      ],
      "metadata": {
        "id": "Mzy5yIxFh04c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Correlation between the third two Series: {arr_3_1.corr(arr_3_2)}')\n"
      ],
      "metadata": {
        "id": "iDKjD1OWh6er"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Correlation matrix and heat maps**\n"
      ],
      "metadata": {
        "id": "23RMX2nIilpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('../../Datasets/diabetes-clean.csv', index_col=0)\n"
      ],
      "metadata": {
        "id": "Hz_2BOuZi7k1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()\n"
      ],
      "metadata": {
        "id": "ota5yrK6i_dx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered = df.drop(columns=['outcome'])\n"
      ],
      "metadata": {
        "id": "7BXSCyjWjBiI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_filtered.corr()\n"
      ],
      "metadata": {
        "id": "qDgG2d6qjDJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's now use a heatmap to visualize this matrix in a way that is easier to interpret:\n"
      ],
      "metadata": {
        "id": "qSg-BnnCjLL9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(8, 6))\n",
        "ax = sns.heatmap(df_filtered.corr(), vmin=-1, vmax=1, annot=True, cmap=\"YlGnBu\", linewidths=.5);\n"
      ],
      "metadata": {
        "id": "lF3HdYS5jNVz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}